{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Federated Learning - RNN for text classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/resilientmax/60DaysOfUdacity/blob/master/Federated%20Learning%20-%20RNN%20for%20text%20classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgsJZ1lUew1m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bc7625f7-8f88-434d-fd11-3bb9371ec5de"
      },
      "source": [
        "!pip install syft"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting syft\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/38/2e/16bdefc78eb089e1efa9704c33b8f76f035a30dc935bedd7cbb22f6dabaa/syft-0.1.21a1-py3-none-any.whl (219kB)\n",
            "\u001b[K     |████████████████████████████████| 225kB 4.9MB/s \n",
            "\u001b[?25hCollecting flask-socketio>=3.3.2 (from syft)\n",
            "  Downloading https://files.pythonhosted.org/packages/4b/68/fe4806d3a0a5909d274367eb9b3b87262906c1515024f46c2443a36a0c82/Flask_SocketIO-4.1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.6/dist-packages (from syft) (0.21.2)\n",
            "Collecting tf-encrypted>=0.5.4 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/55/ff/7dbd5fc77fcec0df1798268a6b72a2ab0150b854761bc39c77d566798f0b/tf_encrypted-0.5.7-py3-none-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 59.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.16.4)\n",
            "Requirement already satisfied: torchvision>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from syft) (0.3.0)\n",
            "Collecting lz4>=2.1.6 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/c6/96bbb3525a63ebc53ea700cc7d37ab9045542d33b4d262d0f0408ad9bbf2/lz4-2.1.10-cp36-cp36m-manylinux1_x86_64.whl (385kB)\n",
            "\u001b[K     |████████████████████████████████| 389kB 50.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: tblib>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.4.0)\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from syft) (1.1.0)\n",
            "Collecting zstd>=1.4.0.0 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/37/6a7ba746ebddbd6cd06de84367515d6bc239acd94fb3e0b1c85788176ca2/zstd-1.4.1.0.tar.gz (454kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 56.4MB/s \n",
            "\u001b[?25hCollecting websockets>=7.0 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c1/d2/bf72435a7d56f94b57efdeae26c76bf0d16f409fd44ff595da745c3fbefd/websockets-8.0.1-cp36-cp36m-manylinux1_x86_64.whl (72kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 36.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: Flask>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from syft) (1.1.1)\n",
            "Collecting websocket-client>=0.56.0 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/19/44753eab1fdb50770ac69605527e8859468f3c0fd7dc5a76dd9c4dbd7906/websocket_client-0.56.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 11.9MB/s \n",
            "\u001b[?25hCollecting msgpack>=0.6.1 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/7e/ae9e91c1bb8d846efafd1f353476e3fd7309778b582d2fb4cea4cc15b9a2/msgpack-0.6.1-cp36-cp36m-manylinux1_x86_64.whl (248kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 50.1MB/s \n",
            "\u001b[?25hCollecting python-socketio>=2.1.0 (from flask-socketio>=3.3.2->syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/1b/57e860a86f2a01be86ae1dacfa0cd8c4dfbfcd4593322268b61b5a07b564/python_socketio-4.2.0-py2.py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 26.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->syft) (0.13.2)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->syft) (1.3.0)\n",
            "Requirement already satisfied: tensorflow<2,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf-encrypted>=0.5.4->syft) (1.14.0)\n",
            "Collecting pyyaml>=5.1 (from tf-encrypted>=0.5.4->syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/65/837fefac7475963d1eccf4aa684c23b95aa6c1d033a2c5965ccb11e22623/PyYAML-5.1.1.tar.gz (274kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 57.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.3.0->syft) (1.12.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.3.0->syft) (4.3.0)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (7.0)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (0.15.5)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (1.1.0)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (2.10.1)\n",
            "Collecting python-engineio>=3.8.0 (from python-socketio>=2.1.0->flask-socketio>=3.3.2->syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bd/b8/0fc389ca5c445051b37b17802f80bbf1b51c1e3b48b772ee608efbb90583/python_engineio-3.8.2.post1-py2.py3-none-any.whl (119kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 53.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.7.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.0.8)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.11.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.2.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (3.7.1)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.15.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.8.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.1.7)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.33.4)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision>=0.3.0->syft) (0.46)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask>=1.0.2->syft) (1.1.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (2.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (3.1.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (41.0.1)\n",
            "Building wheels for collected packages: zstd, pyyaml\n",
            "  Building wheel for zstd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/66/3f/ee/ac08c81af7c1b24a80c746df669ea3cb37542d27877d66ccf4\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/27/a1/775c62ddea7bfa62324fd1f65847ed31c55dadb6051481ba3f\n",
            "Successfully built zstd pyyaml\n",
            "Installing collected packages: python-engineio, python-socketio, flask-socketio, pyyaml, tf-encrypted, lz4, zstd, websockets, websocket-client, msgpack, syft\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Found existing installation: msgpack 0.5.6\n",
            "    Uninstalling msgpack-0.5.6:\n",
            "      Successfully uninstalled msgpack-0.5.6\n",
            "Successfully installed flask-socketio-4.1.0 lz4-2.1.10 msgpack-0.6.1 python-engineio-3.8.2.post1 python-socketio-4.2.0 pyyaml-5.1.1 syft-0.1.21a1 tf-encrypted-0.5.7 websocket-client-0.56.0 websockets-8.0.1 zstd-1.4.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmrxS-fie9ZQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "9525dcbe-0dca-4b23-b7b5-26626507f12c"
      },
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import torch\n",
        "from io import open\n",
        "import glob\n",
        "import os\n",
        "import numpy as np\n",
        "import unicodedata\n",
        "import string\n",
        "import random\n",
        "import torch.nn as nn\n",
        "import time\n",
        "import math\n",
        "import syft as sy\n",
        "import pandas as pd\n",
        "import random\n",
        "from syft.frameworks.torch.federated import utils\n",
        "\n",
        "from syft.workers import WebsocketClientWorker\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0723 06:20:09.048094 140330330281856 secure_random.py:26] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/usr/local/lib/python3.6/dist-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.14.0.so'\n",
            "W0723 06:20:09.062136 140330330281856 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tf_encrypted/session.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OAHngt6fpIU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "4d6bab31-92dd-4c42-a2fe-3d32f0659b26"
      },
      "source": [
        "!wget https://download.pytorch.org/tutorial/data.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-07-23 06:22:36--  https://download.pytorch.org/tutorial/data.zip\n",
            "Resolving download.pytorch.org (download.pytorch.org)... 13.224.29.19, 13.224.29.73, 13.224.29.60, ...\n",
            "Connecting to download.pytorch.org (download.pytorch.org)|13.224.29.19|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2882130 (2.7M) [application/zip]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "\rdata.zip              0%[                    ]       0  --.-KB/s               \rdata.zip            100%[===================>]   2.75M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2019-07-23 06:22:36 (57.8 MB/s) - ‘data.zip’ saved [2882130/2882130]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VdpHvwjfzcN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "889cd780-318b-4f28-ed01-314563ed7d5a"
      },
      "source": [
        "!unzip data.zip"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  data.zip\n",
            "   creating: data/\n",
            "  inflating: data/eng-fra.txt        \n",
            "   creating: data/names/\n",
            "  inflating: data/names/Arabic.txt   \n",
            "  inflating: data/names/Chinese.txt  \n",
            "  inflating: data/names/Czech.txt    \n",
            "  inflating: data/names/Dutch.txt    \n",
            "  inflating: data/names/English.txt  \n",
            "  inflating: data/names/French.txt   \n",
            "  inflating: data/names/German.txt   \n",
            "  inflating: data/names/Greek.txt    \n",
            "  inflating: data/names/Irish.txt    \n",
            "  inflating: data/names/Italian.txt  \n",
            "  inflating: data/names/Japanese.txt  \n",
            "  inflating: data/names/Korean.txt   \n",
            "  inflating: data/names/Polish.txt   \n",
            "  inflating: data/names/Portuguese.txt  \n",
            "  inflating: data/names/Russian.txt  \n",
            "  inflating: data/names/Scottish.txt  \n",
            "  inflating: data/names/Spanish.txt  \n",
            "  inflating: data/names/Vietnamese.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJu0-SJ-fK5v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load all the files in a certain path\n",
        "def findFiles(path):\n",
        "    return glob.glob(path)\n",
        "\n",
        "# Read a file and split into lines\n",
        "def readLines(filename):\n",
        "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
        "    return [unicodeToAscii(line) for line in lines]\n",
        "\n",
        "#convert a string 's' in unicode format to ASCII format\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "        and c in all_letters\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W01TsNhvfQHb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "c68772db-c9d5-4ef6-f510-77b768c76e6d"
      },
      "source": [
        "all_letters = string.ascii_letters + \" .,;'\"\n",
        "n_letters = len(all_letters)\n",
        "\n",
        "#dictionary containing the nation as key and the names as values\n",
        "#Example: category_lines[\"italian\"] = [\"Abandonato\",\"Abatangelo\",\"Abatantuono\",...]\n",
        "category_lines = {}\n",
        "#List containing the different categories in the data\n",
        "all_categories = []\n",
        "\n",
        "for filename in findFiles('data/names/*.txt'):\n",
        "    print(filename)\n",
        "    category = os.path.splitext(os.path.basename(filename))[0]\n",
        "    all_categories.append(category)\n",
        "    lines = readLines(filename)\n",
        "    category_lines[category] = lines   \n",
        "    \n",
        "n_categories = len(all_categories)\n",
        "\n",
        "print(\"Amount of categories:\" + str(n_categories))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data/names/Spanish.txt\n",
            "data/names/German.txt\n",
            "data/names/Irish.txt\n",
            "data/names/Vietnamese.txt\n",
            "data/names/Greek.txt\n",
            "data/names/French.txt\n",
            "data/names/Arabic.txt\n",
            "data/names/Chinese.txt\n",
            "data/names/Polish.txt\n",
            "data/names/Portuguese.txt\n",
            "data/names/Russian.txt\n",
            "data/names/Italian.txt\n",
            "data/names/Czech.txt\n",
            "data/names/Japanese.txt\n",
            "data/names/Dutch.txt\n",
            "data/names/Korean.txt\n",
            "data/names/Scottish.txt\n",
            "data/names/English.txt\n",
            "Amount of categories:18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tg62MHFWfXuy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LanguageDataset(Dataset):\n",
        "    #Constructor is mandatory\n",
        "        def __init__(self, text, labels, transform=None):\n",
        "            self.data = text\n",
        "            self.targets = labels #categories\n",
        "            #self.to_torchtensor()\n",
        "            self.transform = transform\n",
        "        \n",
        "        def to_torchtensor(self):            \n",
        "            self.data = torch.from_numpy(self.text, requires_grad=True)\n",
        "            self.labels = torch.from_numpy(self.targets, requires_grad=True)\n",
        "        \n",
        "        def __len__(self):\n",
        "            #Mandatory\n",
        "            '''Returns:\n",
        "                    Length [int]: Length of Dataset/batches\n",
        "            '''\n",
        "            return len(self.data)\n",
        "    \n",
        "        def __getitem__(self, idx): \n",
        "            #Mandatory \n",
        "            \n",
        "            '''Returns:\n",
        "                     Data [Torch Tensor]: \n",
        "                     Target [ Torch Tensor]:\n",
        "            '''\n",
        "            sample = self.data[idx]\n",
        "            target = self.targets[idx]\n",
        "                    \n",
        "            if self.transform:\n",
        "                sample = self.transform(sample)\n",
        "    \n",
        "            return sample,target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oo4nKWBsgFqC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The list of arguments for our program. We will be needing most of them soon.\n",
        "class Arguments():\n",
        "    def __init__(self):\n",
        "        self.batch_size = 1\n",
        "        self.learning_rate = 0.005\n",
        "        self.epochs = 10000\n",
        "        self.federate_after_n_batches = 15000\n",
        "        self.seed = 1\n",
        "        self.print_every = 200\n",
        "        self.plot_every = 100\n",
        "        self.use_cuda = False\n",
        "        \n",
        "args = Arguments()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNlIvh4zgH3u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "d768348b-1bd0-4fd8-abd6-dde624fa3fc1"
      },
      "source": [
        "#Set of names(X)\n",
        "names_list = []\n",
        "#Set of labels (Y)\n",
        "category_list = []\n",
        "\n",
        "#Convert into a list with corresponding label.\n",
        "\n",
        "for nation, names in category_lines.items():\n",
        "    #iterate over every single name\n",
        "    for name in names:\n",
        "        names_list.append(name)      #input data point\n",
        "        category_list.append(nation) #label\n",
        "        \n",
        "#let's see if it was successfully loaded. Each data sample(X) should have its own corresponding category(Y)\n",
        "print(names_list[1:20])\n",
        "print(category_list[1:20])\n",
        "\n",
        "print(\"\\n \\n Amount of data points loaded: \" + str(len(names_list)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Abano', 'Abarca', 'Abaroa', 'Abascal', 'Abasolo', 'Abel', 'Abello', 'Aberquero', 'Abreu', 'Acosta', 'Agramunt', 'Aiza', 'Alamilla', 'Albert', 'Albuquerque', 'Aldana', 'Alfaro', 'Alvarado', 'Alvarez']\n",
            "['Spanish', 'Spanish', 'Spanish', 'Spanish', 'Spanish', 'Spanish', 'Spanish', 'Spanish', 'Spanish', 'Spanish', 'Spanish', 'Spanish', 'Spanish', 'Spanish', 'Spanish', 'Spanish', 'Spanish', 'Spanish', 'Spanish']\n",
            "\n",
            " \n",
            " Amount of data points loaded: 20074\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvFigLFWgQx5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2353d584-06a3-441a-b5c0-d29517171874"
      },
      "source": [
        "#Assign an integer to every category\n",
        "categories_numerical = pd.factorize(category_list)[0]\n",
        "#Let's wrap our categories with a tensor, so that it can be loaded by LanguageDataset\n",
        "category_tensor = torch.tensor(np.array(categories_numerical), dtype=torch.long)\n",
        "#Ready to be processed by torch.from_numpy in LanguageDataset\n",
        "categories_numpy = np.array(category_tensor)\n",
        "\n",
        "#Let's see a few resulting categories\n",
        "print(names_list[1200:1210])\n",
        "print(categories_numpy[1200:1210])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"O'Rourke\", \"O'Ryan\", \"O'Shea\", \"O'Sullivan\", \"O'Toole\", 'Patrick', 'Peatain', 'Pharlain', 'Power', 'Quigley']\n",
            "[2 2 2 2 2 2 2 2 2 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqHwmK2JgNGw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "a0d06280-8f0e-4098-ecfb-aa9326ac5783"
      },
      "source": [
        "def letterToIndex(letter):\n",
        "    return all_letters.find(letter)\n",
        "    \n",
        "# Just for demonstration, turn a letter into a <1 x n_letters> Tensor\n",
        "def letterToTensor(letter):\n",
        "    tensor = torch.zeros(1, n_letters)\n",
        "    tensor[0][letterToIndex(letter)] = 1\n",
        "    return tensor\n",
        "\n",
        "# Turn a line into a <line_length x 1 x n_letters>,\n",
        "# or an array of one-hot letter vectors\n",
        "def lineToTensor(line):\n",
        "    tensor = torch.zeros(len(line), 1, n_letters) #Daniele: len(max_line_size) was len(line)\n",
        "    for li, letter in enumerate(line):\n",
        "        tensor[li][0][letterToIndex(letter)] = 1\n",
        "    #Daniele: add blank elements over here\n",
        "    return tensor    \n",
        "    \n",
        "    \n",
        "    \n",
        "def list_strings_to_list_tensors(names_list):\n",
        "    lines_tensors = []\n",
        "    for index, line in enumerate(names_list):\n",
        "        lineTensor = lineToTensor(line)\n",
        "        lineNumpy = lineTensor.numpy()\n",
        "        lines_tensors.append(lineNumpy)\n",
        "        \n",
        "    return(lines_tensors)\n",
        "\n",
        "lines_tensors = list_strings_to_list_tensors(names_list)\n",
        "\n",
        "print(names_list[0])\n",
        "print(lines_tensors[0])\n",
        "print(lines_tensors[0].shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Abana\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "\n",
            " [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "\n",
            " [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "(5, 1, 57)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4c1UxTFgVPd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "94cee305-fe88-4c1f-bcb5-8ba055a296b7"
      },
      "source": [
        "max_line_size = max(len(x) for x in lines_tensors)\n",
        "\n",
        "def lineToTensorFillEmpty(line, max_line_size):\n",
        "    tensor = torch.zeros(max_line_size, 1, n_letters) #notice the difference between this method and the previous one\n",
        "    for li, letter in enumerate(line):\n",
        "        tensor[li][0][letterToIndex(letter)] = 1\n",
        "        \n",
        "        #Vectors with (0,0,.... ,0) are placed where there are no characters\n",
        "    return tensor\n",
        "\n",
        "def list_strings_to_list_tensors_fill_empty(names_list):\n",
        "    lines_tensors = []\n",
        "    for index, line in enumerate(names_list):\n",
        "        lineTensor = lineToTensorFillEmpty(line, max_line_size)\n",
        "        lines_tensors.append(lineTensor)\n",
        "    return(lines_tensors)\n",
        "\n",
        "lines_tensors = list_strings_to_list_tensors_fill_empty(names_list)\n",
        "\n",
        "#Let's take a look at what a word now looks like\n",
        "print(names_list[0])\n",
        "print(lines_tensors[0])\n",
        "print(lines_tensors[0].shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Abana\n",
            "tensor([[[0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 1., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "        [[1., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.,  ..., 0., 0., 0.]]])\n",
            "torch.Size([19, 1, 57])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1inGmOagZ9B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ccce7509-7bc7-467e-cfe2-58d703f9a01e"
      },
      "source": [
        "#And finally, from a list, we can create a numpy array with all our word embeddings having the same shape:\n",
        "array_lines_tensors = np.stack(lines_tensors)\n",
        "#However, such operation introduces one extra dimension (look at the dimension with index=2 having size '1')\n",
        "print(array_lines_tensors.shape)\n",
        "#Because that dimension just has size 1, we can get rid of it with the following function call\n",
        "array_lines_proper_dimension = np.squeeze(array_lines_tensors, axis=2)\n",
        "print(array_lines_proper_dimension.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20074, 19, 1, 57)\n",
            "(20074, 19, 57)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCaF6_TMgebo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c4346ab3-491a-4218-c92f-7750be9a62e6"
      },
      "source": [
        "def find_start_index_per_category(category_list):\n",
        "    categories_start_index = {}\n",
        "    \n",
        "    #Initialize every category with an empty list\n",
        "    for category in all_categories:\n",
        "        categories_start_index[category] = []\n",
        "    \n",
        "    #Insert the start index of each category into the dictionary categories_start_index\n",
        "    #Example: \"Italian\" --> 203\n",
        "    #         \"Spanish\" --> 19776\n",
        "    last_category = None\n",
        "    i = 0\n",
        "    for name in names_list:\n",
        "        cur_category = category_list[i]\n",
        "        if(cur_category != last_category):\n",
        "            categories_start_index[cur_category] = i\n",
        "            last_category = cur_category\n",
        "        \n",
        "        i = i + 1\n",
        "        \n",
        "    return(categories_start_index)\n",
        "\n",
        "categories_start_index = find_start_index_per_category(category_list)\n",
        "\n",
        "print(categories_start_index)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Spanish': 0, 'German': 298, 'Irish': 1022, 'Vietnamese': 1254, 'Greek': 1327, 'French': 1530, 'Arabic': 1807, 'Chinese': 3807, 'Polish': 4075, 'Portuguese': 4214, 'Russian': 4288, 'Italian': 13696, 'Czech': 14405, 'Japanese': 14924, 'Dutch': 15915, 'Korean': 16212, 'Scottish': 16306, 'English': 16406}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yrdw6bwgh1L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def randomChoice(l):\n",
        "    rand_value = random.randint(0, len(l) - 1)\n",
        "    return l[rand_value], rand_value\n",
        "\n",
        "\n",
        "def randomTrainingIndex():\n",
        "    category, rand_cat_index = randomChoice(all_categories) #cat = category, it's not a random animal\n",
        "    #rand_line_index is a relative index for a data point within the random category rand_cat_index\n",
        "    line, rand_line_index = randomChoice(category_lines[category])\n",
        "    category_start_index = categories_start_index[category]\n",
        "    absolute_index = category_start_index + rand_line_index\n",
        "    return(absolute_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrIf98I4glzP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "428ed2f2-5ea1-4ab2-fef5-d3a815d6a128"
      },
      "source": [
        "#Two hidden layers, based on simple linear layers\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(RNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        combined = torch.cat((input, hidden), 1)\n",
        "        hidden = self.i2h(combined)\n",
        "        output = self.i2o(combined)\n",
        "        output = self.softmax(output)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, self.hidden_size)\n",
        "\n",
        "#Let's instantiate the neural network already:\n",
        "n_hidden = 128\n",
        "#Instantiate RNN\n",
        "\n",
        "device = torch.device(\"cuda\" if args.use_cuda else \"cpu\")\n",
        "model = RNN(n_letters, n_hidden, n_categories).to(device)\n",
        "#The final softmax layer will produce a probability for each one of our 18 categories\n",
        "print(model)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RNN(\n",
            "  (i2h): Linear(in_features=185, out_features=128, bias=True)\n",
            "  (i2o): Linear(in_features=185, out_features=18, bias=True)\n",
            "  (softmax): LogSoftmax()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrDzoIx-gpSi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Now let's define our workers. You can either use remote workers or virtual workers\n",
        "hook = sy.TorchHook(torch)  # <-- NEW: hook PyTorch ie add extra functionalities to support Federated Learning\n",
        "alice = sy.VirtualWorker(hook, id=\"alice\")  \n",
        "bob = sy.VirtualWorker(hook, id=\"bob\")  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGtUsiOJgtxw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "workers_virtual = [alice, bob]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOxPhyUmgwXt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "langDataset =  LanguageDataset(array_lines_proper_dimension, categories_numpy)\n",
        "\n",
        "#assign the data points and the corresponding categories to workers.\n",
        "federated_train_loader = sy.FederatedDataLoader(\n",
        "            langDataset\n",
        "            .federate(workers_virtual),\n",
        "            batch_size=args.batch_size)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INq_oYxBgy5T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def categoryFromOutput(output):\n",
        "    top_n, top_i = output.topk(1)\n",
        "    category_i = top_i[0].item()\n",
        "    return all_categories[category_i], category_i\n",
        "\n",
        "def timeSince(since):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def fed_avg_every_n_iters(model_pointers, iter, federate_after_n_batches):\n",
        "        models_local = {}\n",
        "        \n",
        "        if(iter % args.federate_after_n_batches == 0):\n",
        "            for worker_name, model_pointer in model_pointers.items():\n",
        "#                #need to assign the model to the worker it belongs to.\n",
        "                models_local[worker_name] = model_pointer.copy().get()\n",
        "            model_avg = utils.federated_avg(models_local)\n",
        "           \n",
        "            for worker in workers_virtual:\n",
        "                model_copied_avg = model_avg.copy()\n",
        "                model_ptr = model_copied_avg.send(worker) \n",
        "                model_pointers[worker.id] = model_ptr\n",
        "                \n",
        "        return(model_pointers)     \n",
        "\n",
        "def fw_bw_pass_model(model_pointers, line_single, category_single):\n",
        "    #get the right initialized model\n",
        "    model_ptr = model_pointers[line_single.location.id]   \n",
        "    line_reshaped = line_single.reshape(max_line_size, 1, len(all_letters))\n",
        "    line_reshaped, category_single = line_reshaped.to(device), category_single.to(device)\n",
        "    #Firstly, initialize hidden layer\n",
        "    hidden_init = model_ptr.initHidden() \n",
        "    #And now zero grad the model\n",
        "    model_ptr.zero_grad()\n",
        "    hidden_ptr = hidden_init.send(line_single.location)\n",
        "    amount_lines_non_zero = len(torch.nonzero(line_reshaped.copy().get()))\n",
        "    #now need to perform forward passes\n",
        "    for i in range(amount_lines_non_zero): \n",
        "        output, hidden_ptr = model_ptr(line_reshaped[i], hidden_ptr) \n",
        "    criterion = nn.NLLLoss()   \n",
        "    loss = criterion(output, category_single) \n",
        "    loss.backward()\n",
        "    \n",
        "    model_got = model_ptr.get() \n",
        "    \n",
        "    #Perform model weights' updates    \n",
        "    for param in model_got.parameters():\n",
        "        param.data.add_(-args.learning_rate, param.grad.data)\n",
        "        \n",
        "        \n",
        "    model_sent = model_got.send(line_single.location.id)\n",
        "    model_pointers[line_single.location.id] = model_sent\n",
        "    \n",
        "    return(model_pointers, loss, output)\n",
        "            \n",
        "  \n",
        "    \n",
        "def train_RNN(n_iters, print_every, plot_every, federate_after_n_batches, list_federated_train_loader):\n",
        "    current_loss = 0\n",
        "    all_losses = []    \n",
        "    \n",
        "    model_pointers = {}\n",
        "    \n",
        "    #Send the initialized model to every single worker just before the training procedure starts\n",
        "    for worker in workers_virtual:\n",
        "        model_copied = model.copy()\n",
        "        model_ptr = model_copied.send(worker) \n",
        "        model_pointers[worker.id] = model_ptr\n",
        "\n",
        "    #extract a random element from the list and perform training on it\n",
        "    for iter in range(1, n_iters + 1):        \n",
        "        random_index = randomTrainingIndex()\n",
        "        line_single, category_single = list_federated_train_loader[random_index]\n",
        "        #print(category_single.copy().get())\n",
        "        line_name = names_list[random_index]\n",
        "        model_pointers, loss, output = fw_bw_pass_model(model_pointers, line_single, category_single)\n",
        "        #model_pointers = fed_avg_every_n_iters(model_pointers, iter, args.federate_after_n_batches)\n",
        "        #Update the current loss a\n",
        "        loss_got = loss.get().item() \n",
        "        current_loss += loss_got\n",
        "        \n",
        "        if iter % plot_every == 0:\n",
        "            all_losses.append(current_loss / plot_every)\n",
        "            current_loss = 0\n",
        "             \n",
        "        if(iter % print_every == 0):\n",
        "            output_got = output.get()  #Without copy()\n",
        "            guess, guess_i = categoryFromOutput(output_got)\n",
        "            category = all_categories[category_single.copy().get().item()]\n",
        "            correct = '✓' if guess == category else '✗ (%s)' % category\n",
        "            print('%d %d%% (%s) %.4f %s / %s %s' % (iter, iter / n_iters * 100, timeSince(start), loss_got, line_name, guess, correct))\n",
        "    return(all_losses, model_pointers)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GPMLUrBg2vN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "55a2ab7b-add3-4ab5-a63c-1913ff8510fc"
      },
      "source": [
        "print(\"Generating list of batches for the workers...\")\n",
        "list_federated_train_loader = list(federated_train_loader)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating list of batches for the workers...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKmUCBNLg51O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 885
        },
        "outputId": "3a4521dc-bf25-4b03-e8db-cbdbfad57666"
      },
      "source": [
        "start = time.time()\n",
        "all_losses, model_pointers = train_RNN(args.epochs, args.print_every, args.plot_every, args.federate_after_n_batches, list_federated_train_loader)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200 2% (0m 8s) 2.7857 Alexandropoulos / Irish ✗ (Greek)\n",
            "400 4% (0m 16s) 2.5867 Kimiyama / Japanese ✓\n",
            "600 6% (0m 23s) 2.8228 Ricchetti / Scottish ✗ (Italian)\n",
            "800 8% (0m 27s) 2.9309 Ganim / Irish ✗ (Arabic)\n",
            "1000 10% (0m 31s) 2.7115 Thien / German ✗ (Chinese)\n",
            "1200 12% (0m 35s) 2.7394 Seow / German ✗ (Chinese)\n",
            "1400 14% (0m 39s) 2.5064 Jacques / Greek ✗ (French)\n",
            "1600 16% (0m 42s) 1.8358 Sada / Japanese ✓\n",
            "1800 18% (0m 46s) 2.1343 Sanchez / German ✗ (Spanish)\n",
            "2000 20% (0m 49s) 2.3544 Muyskens / English ✗ (Dutch)\n",
            "2200 22% (0m 53s) 1.8127 Telis / Greek ✓\n",
            "2400 24% (0m 56s) 2.0137 Rompaij / Japanese ✗ (Dutch)\n",
            "2600 26% (1m 0s) 2.0017 Zavatsky / Scottish ✗ (Russian)\n",
            "2800 28% (1m 4s) 1.9977 Topp / Czech ✗ (English)\n",
            "3000 30% (1m 7s) 1.7958 Naomhan / Irish ✓\n",
            "3200 32% (1m 11s) 2.1679 Havlice / English ✗ (Czech)\n",
            "3400 34% (1m 14s) 2.1803 Thibault / Irish ✗ (French)\n",
            "3600 36% (1m 18s) 2.0113 Seto / Chinese ✓\n",
            "3800 38% (1m 22s) 1.4553 Kurusu / Japanese ✓\n",
            "4000 40% (1m 25s) 1.9338 King / Korean ✗ (Scottish)\n",
            "4200 42% (1m 29s) 2.0656 Cabello / Portuguese ✗ (Spanish)\n",
            "4400 44% (1m 32s) 1.9054 Vo / Chinese ✗ (Vietnamese)\n",
            "4600 46% (1m 36s) 0.9120 Karahalios / Greek ✓\n",
            "4800 48% (1m 40s) 0.6566 Paschalis / Greek ✓\n",
            "5000 50% (1m 43s) 1.4973 Guan / Vietnamese ✗ (Chinese)\n",
            "5200 52% (1m 47s) 1.6396 Macikova / Dutch ✗ (Czech)\n",
            "5400 54% (1m 50s) 2.2547 Michel / Irish ✗ (Spanish)\n",
            "5600 56% (1m 54s) 1.8280 Ruadhan / Irish ✓\n",
            "5800 57% (1m 57s) 1.4004 O'Ryan / Irish ✓\n",
            "6000 60% (2m 1s) 1.9257 Fionn / Arabic ✗ (Irish)\n",
            "6200 62% (2m 5s) 1.0057 See  / Chinese ✓\n",
            "6400 64% (2m 8s) 1.1217 Chen / Chinese ✓\n",
            "6600 66% (2m 12s) 1.8529 Klerken / Scottish ✗ (Dutch)\n",
            "6800 68% (2m 15s) 1.5687 Heppenheimer / German ✓\n",
            "7000 70% (2m 19s) 1.8966 Schwarz / Japanese ✗ (Czech)\n",
            "7200 72% (2m 23s) 1.6357 Simpson / English ✗ (Scottish)\n",
            "7400 74% (2m 26s) 1.8960 Otten / English ✗ (Dutch)\n",
            "7600 76% (2m 30s) 1.8252 Silva / Arabic ✗ (Portuguese)\n",
            "7800 78% (2m 33s) 1.9614 Elling / Czech ✗ (English)\n",
            "8000 80% (2m 37s) 2.0187 Fuentes / Arabic ✗ (Spanish)\n",
            "8200 82% (2m 41s) 1.6468 Weeber / German ✓\n",
            "8400 84% (2m 44s) 1.1638 Fortunato / Italian ✓\n",
            "8600 86% (2m 48s) 1.9572 De laurentis / Dutch ✗ (Italian)\n",
            "8800 88% (2m 51s) 1.7975 Obuchi / Italian ✗ (Japanese)\n",
            "9000 90% (2m 55s) 1.5507 Blaise / French ✓\n",
            "9200 92% (2m 58s) 2.2147 Sitko / Portuguese ✗ (Polish)\n",
            "9400 94% (3m 2s) 0.5802 Koulaxizis / Greek ✓\n",
            "9600 96% (3m 5s) 2.0896 Nartey / Czech ✗ (English)\n",
            "9800 98% (3m 9s) 2.1554 Burns / English ✗ (Scottish)\n",
            "10000 100% (3m 13s) 2.7157 Bruhn / Arabic ✗ (German)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ux3X43vshA0x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "75698764-c6e9-44a7-d7ef-dfa812d7f70f"
      },
      "source": [
        "plt.figure()\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel('Epochs (100s)')\n",
        "plt.plot(all_losses)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fa07b954ef0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nk37mAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJjfKrX2hGpJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "a16c1c92-6187-4679-c31d-5fcad3989180"
      },
      "source": [
        "input_line = \"Daniele\"\n",
        "model_remote = model_pointers[\"alice\"]\n",
        "line_tensor = lineToTensor(input_line)\n",
        "line_tensor\n",
        "line_remote = line_tensor.send(alice)\n",
        "hidden = model_remote.initHidden()\n",
        "hidden_remote = hidden.copy().send(alice)\n",
        "hidden_remote\n",
        "with torch.no_grad():\n",
        "    for i in range(line_remote.shape[0]):\n",
        "        output, hidden_remote = model_remote(line_remote[i], hidden_remote)\n",
        "        \n",
        "n_predictions = 3\n",
        "topv, topi = output.copy().get().topk(n_predictions, 1, True)\n",
        "topv\n",
        "\n",
        "predictions = []\n",
        "\n",
        "\n",
        "for i in range(n_predictions):\n",
        "            value = topv[0][i].item()\n",
        "            category_index = topi[0][i].item()\n",
        "            print('(%.2f) %s' % (value, all_categories[category_index]))\n",
        "            predictions.append([value, all_categories[category_index]])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(-1.66) Irish\n",
            "(-1.76) Portuguese\n",
            "(-1.80) French\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIKl5VrVhLz7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(model, input_line, worker, n_predictions=3):\n",
        "    model = model.copy().get()\n",
        "    print('\\n> %s' % input_line)\n",
        "    model_remote = model.send(worker)\n",
        "    line_tensor = lineToTensor(input_line)\n",
        "    line_remote = line_tensor.copy().send(worker)\n",
        "    #line_tensor = lineToTensor(input_line)\n",
        "    #output = evaluate(model, line_remote)\n",
        "    # Get top N categories\n",
        "    hidden = model_remote.initHidden()\n",
        "    hidden_remote = hidden.copy().send(worker)\n",
        "        \n",
        "    with torch.no_grad():\n",
        "        for i in range(line_remote.shape[0]):\n",
        "            output, hidden_remote = model_remote(line_remote[i], hidden_remote)\n",
        "        \n",
        "    topv, topi = output.copy().get().topk(n_predictions, 1, True)\n",
        "    predictions = []\n",
        "\n",
        "    for i in range(n_predictions):\n",
        "        value = topv[0][i].item()\n",
        "        category_index = topi[0][i].item()\n",
        "        print('(%.2f) %s' % (value, all_categories[category_index]))\n",
        "        predictions.append([value, all_categories[category_index]])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0M44Qc2_hQSt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "62e1aae3-4ace-494d-e56b-4bed4d48912b"
      },
      "source": [
        "predict(model_pointers[\"alice\"], \"Qing\", alice)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "> Qing\n",
            "(-0.59) Chinese\n",
            "(-1.15) Vietnamese\n",
            "(-3.25) Arabic\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wq8U2R9IhTwe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}