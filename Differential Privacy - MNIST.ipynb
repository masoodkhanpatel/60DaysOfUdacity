{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Differential Privacy - MNIST.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/resilientmax/60DaysOfUdacity/blob/master/Differential%20Privacy%20-%20MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKxLTo1A5mz2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "# Transform the image to a tensor and normalize it\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "# Load the train and test data by using the transform\n",
        "train_data = datasets.MNIST(root='data', train=True, download=True, transform=transform)\n",
        "test_data = datasets.MNIST(root='data', train=False, download=True, transform=transform)\n",
        "num_teachers = 10 # Define the num of teachers\n",
        "batch_size = 64 # Teacher batch size\n",
        "\n",
        "def get_data_loaders(train_data, num_teachers):\n",
        "    \"\"\" Function to create data loaders for the Teacher classifier \"\"\"\n",
        "    teacher_loaders = []\n",
        "    data_size = len(train_data) // num_teachers\n",
        "    \n",
        "    for i in range(data_size):\n",
        "        indices = list(range(i*data_size, (i+1)*data_size))\n",
        "        subset_data = Subset(train_data, indices)\n",
        "        loader = torch.utils.data.DataLoader(subset_data, batch_size=batch_size)\n",
        "        teacher_loaders.append(loader)\n",
        "        \n",
        "    return teacher_loaders\n",
        "\n",
        "teacher_loaders = get_data_loaders(train_data, num_teachers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWTwE7cc5yvW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the public dataset by using 90% of the Test data as train #data and remaining 10% as test data.\n",
        "\n",
        "student_train_data = Subset(test_data, list(range(9000)))\n",
        "student_test_data = Subset(test_data, list(range(9000, 10000)))\n",
        "\n",
        "student_train_loader = torch.utils.data.DataLoader(student_train_data, batch_size=batch_size)\n",
        "student_test_loader = torch.utils.data.DataLoader(student_test_data, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRnq2mpV50Gn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    \"\"\" A Simple Feed Forward Neural Network. \n",
        "        A CNN can also be used for this problem \n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.conv2_drop = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(320, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "        x = x.view(-1, 320)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTwHQ8126VHV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, trainloader, criterion, optimizer, epochs=10):\n",
        "    \"\"\" This function trains a single Classifier model \"\"\"\n",
        "    running_loss = 0\n",
        "    for e in range(epochs):\n",
        "        model.train()\n",
        "        \n",
        "        for images, labels in trainloader:\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            output = model.forward(images)\n",
        "            loss = criterion(output, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            running_loss += loss.item()\n",
        "    \n",
        "def predict(model, dataloader):\n",
        "    \"\"\" This function predicts labels for a dataset \n",
        "        given the model and dataloader as inputs. \n",
        "    \"\"\"\n",
        "    outputs = torch.zeros(0, dtype=torch.long)\n",
        "    model.eval()\n",
        "    \n",
        "    for images, labels in dataloader:\n",
        "        output = model.forward(images)\n",
        "        ps = torch.argmax(torch.exp(output), dim=1)\n",
        "        outputs = torch.cat((outputs, ps))\n",
        "        \n",
        "    return outputs\n",
        "  \n",
        "def train_models(num_teachers):\n",
        "    \"\"\" Trains *num_teacher* models (num_teachers being the number of teacher classifiers) \"\"\"\n",
        "    models = []\n",
        "    for i in range(num_teachers):\n",
        "        model = Classifier()\n",
        "        criterion = nn.NLLLoss()\n",
        "        optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
        "        train(model, teacher_loaders[i], criterion, optimizer)\n",
        "        models.append(model)\n",
        "    return models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfceBlAh8EnY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "55dc1019-ddbf-4fcb-99fb-099f6d98567a"
      },
      "source": [
        "models = train_models(num_teachers)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkrJlVQn6ZGY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "a2dbc2fb-0311-4433-954f-6983f684dde0"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "epsilon = 0.2\n",
        "\n",
        "def aggregated_teacher(models, dataloader, epsilon):\n",
        "    \"\"\" Take predictions from individual teacher model and \n",
        "        creates the true labels for the student after adding \n",
        "        laplacian noise to them \n",
        "    \"\"\"\n",
        "    preds = torch.torch.zeros((len(models), 9000), dtype=torch.long)\n",
        "    for i, model in enumerate(models):\n",
        "        results = predict(model, dataloader)\n",
        "        preds[i] = results\n",
        "    \n",
        "    labels = np.array([]).astype(int)\n",
        "    for image_preds in np.transpose(preds):\n",
        "        label_counts = np.bincount(image_preds, minlength=10)\n",
        "        beta = 1 / epsilon\n",
        "\n",
        "        for i in range(len(label_counts)):\n",
        "            label_counts[i] += np.random.laplace(0, beta, 1)\n",
        "\n",
        "        new_label = np.argmax(label_counts)\n",
        "        labels = np.append(labels, new_label)\n",
        "    \n",
        "    return preds.numpy(), labels\n",
        "  \n",
        "teacher_models = models\n",
        "preds, student_labels = aggregated_teacher(teacher_models, student_train_loader, epsilon)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMR6jV7Q6eUP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "outputId": "60aa9bf9-73a0-4a2c-c1ee-e1ff4503e453"
      },
      "source": [
        "def student_loader(student_train_loader, labels):\n",
        "    for i, (data, _) in enumerate(iter(student_train_loader)):\n",
        "        yield data, torch.from_numpy(labels[i*len(data): (i+1)*len(data)])\n",
        "        \n",
        "student_model = Classifier()\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.Adam(student_model.parameters(), lr=0.003)\n",
        "epochs = 10\n",
        "steps = 0\n",
        "running_loss = 0\n",
        "for e in range(epochs):\n",
        "    student_model.train()\n",
        "    train_loader = student_loader(student_train_loader, student_labels)\n",
        "    for images, labels in train_loader:\n",
        "        steps += 1\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        output = student_model.forward(images)\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        \n",
        "        if steps % 50 == 0:\n",
        "            test_loss = 0\n",
        "            accuracy = 0\n",
        "            student_model.eval()\n",
        "            with torch.no_grad():\n",
        "                for images, labels in student_test_loader:\n",
        "                    log_ps = student_model(images)\n",
        "                    test_loss += criterion(log_ps, labels).item()\n",
        "                    \n",
        "                    # Accuracy\n",
        "                    ps = torch.exp(log_ps)\n",
        "                    top_p, top_class = ps.topk(1, dim=1)\n",
        "                    equals = top_class == labels.view(*top_class.shape)\n",
        "                    accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
        "            student_model.train()\n",
        "            print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
        "                  \"Training Loss: {:.3f}.. \".format(running_loss/len(student_train_loader)),\n",
        "                  \"Test Loss: {:.3f}.. \".format(test_loss/len(student_test_loader)),\n",
        "                  \"Test Accuracy: {:.3f}\".format(accuracy/len(student_test_loader)))\n",
        "            running_loss = 0"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/10..  Training Loss: 0.810..  Test Loss: 2.142..  Test Accuracy: 0.440\n",
            "Epoch: 1/10..  Training Loss: 0.765..  Test Loss: 1.685..  Test Accuracy: 0.723\n",
            "Epoch: 2/10..  Training Loss: 0.767..  Test Loss: 1.661..  Test Accuracy: 0.765\n",
            "Epoch: 2/10..  Training Loss: 0.749..  Test Loss: 1.619..  Test Accuracy: 0.829\n",
            "Epoch: 2/10..  Training Loss: 0.730..  Test Loss: 1.577..  Test Accuracy: 0.852\n",
            "Epoch: 3/10..  Training Loss: 0.738..  Test Loss: 1.311..  Test Accuracy: 0.831\n",
            "Epoch: 3/10..  Training Loss: 0.727..  Test Loss: 1.265..  Test Accuracy: 0.879\n",
            "Epoch: 3/10..  Training Loss: 0.714..  Test Loss: 1.342..  Test Accuracy: 0.899\n",
            "Epoch: 4/10..  Training Loss: 0.723..  Test Loss: 1.274..  Test Accuracy: 0.883\n",
            "Epoch: 4/10..  Training Loss: 0.719..  Test Loss: 1.210..  Test Accuracy: 0.912\n",
            "Epoch: 4/10..  Training Loss: 0.714..  Test Loss: 1.360..  Test Accuracy: 0.916\n",
            "Epoch: 5/10..  Training Loss: 0.717..  Test Loss: 1.239..  Test Accuracy: 0.918\n",
            "Epoch: 5/10..  Training Loss: 0.709..  Test Loss: 1.313..  Test Accuracy: 0.904\n",
            "Epoch: 5/10..  Training Loss: 0.714..  Test Loss: 1.225..  Test Accuracy: 0.914\n",
            "Epoch: 6/10..  Training Loss: 0.711..  Test Loss: 1.282..  Test Accuracy: 0.910\n",
            "Epoch: 6/10..  Training Loss: 0.699..  Test Loss: 1.147..  Test Accuracy: 0.929\n",
            "Epoch: 7/10..  Training Loss: 0.702..  Test Loss: 1.325..  Test Accuracy: 0.916\n",
            "Epoch: 7/10..  Training Loss: 0.705..  Test Loss: 1.329..  Test Accuracy: 0.927\n",
            "Epoch: 7/10..  Training Loss: 0.692..  Test Loss: 1.222..  Test Accuracy: 0.913\n",
            "Epoch: 8/10..  Training Loss: 0.709..  Test Loss: 1.256..  Test Accuracy: 0.925\n",
            "Epoch: 8/10..  Training Loss: 0.701..  Test Loss: 1.123..  Test Accuracy: 0.934\n",
            "Epoch: 8/10..  Training Loss: 0.689..  Test Loss: 1.187..  Test Accuracy: 0.939\n",
            "Epoch: 9/10..  Training Loss: 0.705..  Test Loss: 1.087..  Test Accuracy: 0.927\n",
            "Epoch: 9/10..  Training Loss: 0.703..  Test Loss: 1.114..  Test Accuracy: 0.934\n",
            "Epoch: 9/10..  Training Loss: 0.690..  Test Loss: 1.173..  Test Accuracy: 0.937\n",
            "Epoch: 10/10..  Training Loss: 0.704..  Test Loss: 1.152..  Test Accuracy: 0.940\n",
            "Epoch: 10/10..  Training Loss: 0.689..  Test Loss: 1.126..  Test Accuracy: 0.937\n",
            "Epoch: 10/10..  Training Loss: 0.694..  Test Loss: 1.207..  Test Accuracy: 0.933\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsUc-E9g9nI6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "da627811-536e-4d4c-83b4-d9de32a182a1"
      },
      "source": [
        "!pip install syft"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting syft\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/38/2e/16bdefc78eb089e1efa9704c33b8f76f035a30dc935bedd7cbb22f6dabaa/syft-0.1.21a1-py3-none-any.whl (219kB)\n",
            "\r\u001b[K     |█▌                              | 10kB 15.6MB/s eta 0:00:01\r\u001b[K     |███                             | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |████▌                           | 30kB 3.2MB/s eta 0:00:01\r\u001b[K     |██████                          | 40kB 2.1MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 51kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████                       | 61kB 3.1MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 71kB 3.6MB/s eta 0:00:01\r\u001b[K     |████████████                    | 81kB 4.1MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 92kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 102kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 112kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 122kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 133kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 143kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 153kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 163kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 174kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 184kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 194kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 204kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 215kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 225kB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.16.4)\n",
            "Collecting lz4>=2.1.6 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/c6/96bbb3525a63ebc53ea700cc7d37ab9045542d33b4d262d0f0408ad9bbf2/lz4-2.1.10-cp36-cp36m-manylinux1_x86_64.whl (385kB)\n",
            "\u001b[K     |████████████████████████████████| 389kB 55.4MB/s \n",
            "\u001b[?25hCollecting tf-encrypted>=0.5.4 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/55/ff/7dbd5fc77fcec0df1798268a6b72a2ab0150b854761bc39c77d566798f0b/tf_encrypted-0.5.7-py3-none-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 57.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from syft) (0.3.0)\n",
            "Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.6/dist-packages (from syft) (0.21.2)\n",
            "Collecting flask-socketio>=3.3.2 (from syft)\n",
            "  Downloading https://files.pythonhosted.org/packages/4b/68/fe4806d3a0a5909d274367eb9b3b87262906c1515024f46c2443a36a0c82/Flask_SocketIO-4.1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: Flask>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from syft) (1.1.1)\n",
            "Collecting websockets>=7.0 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c1/d2/bf72435a7d56f94b57efdeae26c76bf0d16f409fd44ff595da745c3fbefd/websockets-8.0.1-cp36-cp36m-manylinux1_x86_64.whl (72kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 32.7MB/s \n",
            "\u001b[?25hCollecting zstd>=1.4.0.0 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/37/6a7ba746ebddbd6cd06de84367515d6bc239acd94fb3e0b1c85788176ca2/zstd-1.4.1.0.tar.gz (454kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 65.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: tblib>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.4.0)\n",
            "Collecting msgpack>=0.6.1 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/7e/ae9e91c1bb8d846efafd1f353476e3fd7309778b582d2fb4cea4cc15b9a2/msgpack-0.6.1-cp36-cp36m-manylinux1_x86_64.whl (248kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 34.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from syft) (1.1.0)\n",
            "Collecting websocket-client>=0.56.0 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/19/44753eab1fdb50770ac69605527e8859468f3c0fd7dc5a76dd9c4dbd7906/websocket_client-0.56.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 62.1MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1 (from tf-encrypted>=0.5.4->syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/65/837fefac7475963d1eccf4aa684c23b95aa6c1d033a2c5965ccb11e22623/PyYAML-5.1.1.tar.gz (274kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 65.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow<2,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf-encrypted>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.3.0->syft) (4.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.3.0->syft) (1.12.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->syft) (1.3.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->syft) (0.13.2)\n",
            "Collecting python-socketio>=2.1.0 (from flask-socketio>=3.3.2->syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/1b/57e860a86f2a01be86ae1dacfa0cd8c4dfbfcd4593322268b61b5a07b564/python_socketio-4.2.0-py2.py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 22.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (7.0)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (1.1.0)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (2.10.1)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (0.15.5)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.11.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.33.4)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.7.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (3.7.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.15.0)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.1.7)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.2.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.8.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.0.8)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision>=0.3.0->syft) (0.46)\n",
            "Collecting python-engineio>=3.8.0 (from python-socketio>=2.1.0->flask-socketio>=3.3.2->syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bd/b8/0fc389ca5c445051b37b17802f80bbf1b51c1e3b48b772ee608efbb90583/python_engineio-3.8.2.post1-py2.py3-none-any.whl (119kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 53.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask>=1.0.2->syft) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (41.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (3.1.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (2.8.0)\n",
            "Building wheels for collected packages: zstd, pyyaml\n",
            "  Building wheel for zstd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/66/3f/ee/ac08c81af7c1b24a80c746df669ea3cb37542d27877d66ccf4\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/27/a1/775c62ddea7bfa62324fd1f65847ed31c55dadb6051481ba3f\n",
            "Successfully built zstd pyyaml\n",
            "Installing collected packages: lz4, pyyaml, tf-encrypted, python-engineio, python-socketio, flask-socketio, websockets, zstd, msgpack, websocket-client, syft\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Found existing installation: msgpack 0.5.6\n",
            "    Uninstalling msgpack-0.5.6:\n",
            "      Successfully uninstalled msgpack-0.5.6\n",
            "Successfully installed flask-socketio-4.1.0 lz4-2.1.10 msgpack-0.6.1 python-engineio-3.8.2.post1 python-socketio-4.2.0 pyyaml-5.1.1 syft-0.1.21a1 tf-encrypted-0.5.7 websocket-client-0.56.0 websockets-8.0.1 zstd-1.4.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiYPllAb6jSs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "550ec2fe-cdc6-47da-e714-4925054e6dfd"
      },
      "source": [
        "from syft.frameworks.torch.differential_privacy import pate\n",
        "\n",
        "data_dep_eps, data_ind_eps = pate.perform_analysis(teacher_preds=preds, indices=student_labels, noise_eps=epsilon, delta=1e-5)\n",
        "print(\"Data Independent Epsilon:\", data_ind_eps)\n",
        "print(\"Data Dependent Epsilon:\", data_dep_eps)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0721 19:16:51.093476 139914303608704 secure_random.py:26] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/usr/local/lib/python3.6/dist-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.14.0.so'\n",
            "W0721 19:16:51.111101 139914303608704 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tf_encrypted/session.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Data Independent Epsilon: 1451.5129254649705\n",
            "Data Dependent Epsilon: 1451.5129254651165\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3RVlLJt9w-K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}